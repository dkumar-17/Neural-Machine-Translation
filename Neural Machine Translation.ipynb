{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Neural Machine Translation French-English.ipynb","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Downloading the [Zip file](http://www.manythings.org/anki/fra-eng.zip)","metadata":{"id":"NwAAPrdNFoH0"}},{"cell_type":"code","source":"!wget http://www.manythings.org/anki/fra-eng.zip","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UDBptzV8z6Lj","outputId":"6758a032-30ed-4af2-c741-aa059f42e129","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:01:48.624996Z","iopub.execute_input":"2025-01-29T17:01:48.625280Z","iopub.status.idle":"2025-01-29T17:01:49.483615Z","shell.execute_reply.started":"2025-01-29T17:01:48.625249Z","shell.execute_reply":"2025-01-29T17:01:49.482572Z"}},"outputs":[{"name":"stdout","text":"--2025-01-29 17:01:48--  http://www.manythings.org/anki/fra-eng.zip\nResolving www.manythings.org (www.manythings.org)... 173.254.30.110\nConnecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7943074 (7.6M) [application/zip]\nSaving to: ‘fra-eng.zip’\n\nfra-eng.zip         100%[===================>]   7.57M  13.2MB/s    in 0.6s    \n\n2025-01-29 17:01:49 (13.2 MB/s) - ‘fra-eng.zip’ saved [7943074/7943074]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Extracting the Zip file**","metadata":{"id":"SqmsUr54GM8M"}},{"cell_type":"code","source":"import zipfile\nzip = zipfile.ZipFile('fra-eng.zip')\nzip.extractall()","metadata":{"id":"R7_XKmpIJFT1","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:01:49.484730Z","iopub.execute_input":"2025-01-29T17:01:49.485065Z","iopub.status.idle":"2025-01-29T17:01:49.678268Z","shell.execute_reply.started":"2025-01-29T17:01:49.485034Z","shell.execute_reply":"2025-01-29T17:01:49.677461Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**Dependencies**","metadata":{"id":"-JIkRGU6GTrj"}},{"cell_type":"code","source":"import string,re\nfrom unicodedata import normalize\nfrom numpy import array,argmax\nfrom pickle import load,dump\nfrom numpy.random import rand,shuffle","metadata":{"id":"F1NLrlQkMHhH","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:01:49.679121Z","iopub.execute_input":"2025-01-29T17:01:49.679421Z","iopub.status.idle":"2025-01-29T17:01:49.683601Z","shell.execute_reply.started":"2025-01-29T17:01:49.679400Z","shell.execute_reply":"2025-01-29T17:01:49.682735Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import LSTM, Dense, Embedding, RepeatVector, TimeDistributed","metadata":{"id":"dvlzRVWJGeq8","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:01:49.685865Z","iopub.execute_input":"2025-01-29T17:01:49.686091Z","iopub.status.idle":"2025-01-29T17:02:01.537040Z","shell.execute_reply.started":"2025-01-29T17:01:49.686073Z","shell.execute_reply":"2025-01-29T17:02:01.536384Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"**Loading the file and reading the content of the file**","metadata":{"id":"2Di1MTtIJugr"}},{"cell_type":"code","source":"# load file into memory\ndef load_file(filename):\n\t# open the file as read only\n\tfile = open(filename, mode='rt', encoding='utf-8')\n\t# read all text\n\ttext = file.read()\n\t# close the file\n\tfile.close()\n\treturn text","metadata":{"id":"p1uiIFmaLbZg","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:01.538257Z","iopub.execute_input":"2025-01-29T17:02:01.538795Z","iopub.status.idle":"2025-01-29T17:02:01.542729Z","shell.execute_reply.started":"2025-01-29T17:02:01.538771Z","shell.execute_reply":"2025-01-29T17:02:01.541868Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"**Splitting the sentence into pairs**","metadata":{"id":"UQ6vhjhDJ5jy"}},{"cell_type":"code","source":"# split a loaded document into sentences\ndef splitting_sentence(doc):\n\tsentences = doc.strip().split('\\n')\n\tpairs = [sentence.split('\\t') for sentence in  sentences]\n\treturn pairs","metadata":{"id":"QV6559a1LvQI","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:01.543435Z","iopub.execute_input":"2025-01-29T17:02:01.543675Z","iopub.status.idle":"2025-01-29T17:02:01.570249Z","shell.execute_reply.started":"2025-01-29T17:02:01.543631Z","shell.execute_reply":"2025-01-29T17:02:01.569435Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"**Cleaning the pairs**","metadata":{"id":"bc2F_iwDKCAC"}},{"cell_type":"code","source":"# cleaning a list of sentences and creating pairs\n\ndef clean_pairs(sentences):\n\tcleaned = list()\n \n\t# preparing regex for char filtering\n\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n\n\t# preparing translation table for removing punctuation\n\ttable = str.maketrans('', '', string.punctuation)\n\n  # iterating over each pair\n\tfor pair in sentences:\n\t\tclean_pair = list()\n  \n\t\tfor sentence in pair:\n\t\t\t# normalizing unicode characters\n\t\t\tsentence = normalize('NFD', sentence).encode('ascii', 'ignore')\n\t\t\tsentence = sentence.decode('UTF-8')\n\t\t\t# tokenizing on white space\n\t\t\tsentence = sentence.split()\n\t\t\t# converting to lowercase\n\t\t\tsentence = [word.lower() for word in sentence]\n\t\t\t# removing punctuation from each token\n\t\t\tsentence = [word.translate(table) for word in sentence]\n\t\t\t# removing non-printable chars form each token\n\t\t\tsentence = [re_print.sub('', w) for w in sentence]\n\t\t\t# removing tokens with numbers in them\n\t\t\tsentence = [word for word in sentence if word.isalpha()]\n\t\t\t# storing as string\n\t\t\tclean_pair.append(' '.join(sentence))\n\t\tcleaned.append(clean_pair)\n\treturn array(cleaned)","metadata":{"id":"2p-ZO41bL3U3","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:01.571004Z","iopub.execute_input":"2025-01-29T17:02:01.571322Z","iopub.status.idle":"2025-01-29T17:02:01.585455Z","shell.execute_reply.started":"2025-01-29T17:02:01.571290Z","shell.execute_reply":"2025-01-29T17:02:01.584681Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"**Saving the Cleaned data**","metadata":{"id":"IfpzMDIDMIvC"}},{"cell_type":"code","source":"def saving_clean_data(sentences, filename):\n\tdump(sentences, open(filename, 'wb'))\n\tprint(filename,': Saved')","metadata":{"id":"Ovtlpsp3MVU_","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:01.586350Z","iopub.execute_input":"2025-01-29T17:02:01.586554Z","iopub.status.idle":"2025-01-29T17:02:01.600918Z","shell.execute_reply.started":"2025-01-29T17:02:01.586532Z","shell.execute_reply":"2025-01-29T17:02:01.600223Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"**Saving data in .pkl format**","metadata":{"id":"b3RLnKIVMO5J"}},{"cell_type":"code","source":"# load dataset\n\nfilename = 'fra.txt'\ndoc = load_file(filename)\n\n# split into english-french pairs\npairs = splitting_sentence(doc)\n\n# clean sentences\nclean_pairs = clean_pairs(pairs)\n\n# save clean pairs to file\nsaving_clean_data(clean_pairs, 'english-french.pkl')\n\nprint('English','-->',\"French\")\n# spot check\nfor i in range(25):\n\tprint(clean_pairs[i,0],'-->',clean_pairs[i,1])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tkoxnpbMjLn","outputId":"4d699ce9-a303-4fba-f01c-ab8603e5ee95","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:01.601537Z","iopub.execute_input":"2025-01-29T17:02:01.601821Z","iopub.status.idle":"2025-01-29T17:02:11.537401Z","shell.execute_reply.started":"2025-01-29T17:02:01.601794Z","shell.execute_reply":"2025-01-29T17:02:11.533535Z"}},"outputs":[{"name":"stdout","text":"english-french.pkl : Saved\nEnglish --> French\ngo --> va\ngo --> marche\ngo --> en route\ngo --> bouge\nhi --> salut\nhi --> salut\nrun --> cours\nrun --> courez\nrun --> prenez vos jambes a vos cous\nrun --> file\nrun --> filez\nrun --> cours\nrun --> fuyez\nrun --> fuyons\nrun --> cours\nrun --> courez\nrun --> prenez vos jambes a vos cous\nrun --> file\nrun --> filez\nrun --> cours\nrun --> fuyez\nrun --> fuyons\nwho --> qui\nwow --> ca alors\nwow --> waouh\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**Loading the cleaned data**","metadata":{"id":"Gq5SVqTtcQtS"}},{"cell_type":"code","source":"# load a clean dataset\ndef loading_cleaned_data(filename):\n\treturn load(open(filename, 'rb'))","metadata":{"id":"L5oB73alcVRO","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:11.538159Z","iopub.execute_input":"2025-01-29T17:02:11.538416Z","iopub.status.idle":"2025-01-29T17:02:11.541933Z","shell.execute_reply.started":"2025-01-29T17:02:11.538392Z","shell.execute_reply":"2025-01-29T17:02:11.541100Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# load dataset\ndata = loading_cleaned_data('english-french.pkl')\nprint(data.shape) ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORWdTFwKPh7G","outputId":"8eef7755-b8e7-42fa-f77a-3e0ca06b35c0","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:11.542689Z","iopub.execute_input":"2025-01-29T17:02:11.542994Z","iopub.status.idle":"2025-01-29T17:02:12.168398Z","shell.execute_reply.started":"2025-01-29T17:02:11.542958Z","shell.execute_reply":"2025-01-29T17:02:12.167673Z"}},"outputs":[{"name":"stdout","text":"(232736, 3)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**Scaling of data** \n\n**Size**\n\n1.Dataset - 20000\n\n2.Training - 18000\n\n3.Testing - 2000   \n\n","metadata":{"id":"p5RbRHzlL_oF"}},{"cell_type":"code","source":"# reducing dataset size (scaling) \n\nnew_data_size = 20000\ndataset = data[:new_data_size, :]\n\n# randomly shuffling the dataset to get proper training and testing data\nshuffle(dataset)\n\n# splitting into training and testing (90%-10%)\ntrain, test = dataset[:18000], dataset[18000:]\n\n# saving the cleaned data,train data and test data \nsaving_clean_data(dataset, 'english-french-both.pkl')\nsaving_clean_data(train, 'english-french-train.pkl')\nsaving_clean_data(test, 'english-french-test.pkl')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjGXDVkDcpAy","outputId":"1fff4400-c7a2-4374-8b51-23fe1b2f83d4","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:12.169324Z","iopub.execute_input":"2025-01-29T17:02:12.169636Z","iopub.status.idle":"2025-01-29T17:02:12.492292Z","shell.execute_reply.started":"2025-01-29T17:02:12.169604Z","shell.execute_reply":"2025-01-29T17:02:12.491246Z"}},"outputs":[{"name":"stdout","text":"english-french-both.pkl : Saved\nenglish-french-train.pkl : Saved\nenglish-french-test.pkl : Saved\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# loading datasets and saving it into variables\ndataset = loading_cleaned_data('english-french-both.pkl')\ntrain = loading_cleaned_data('english-french-train.pkl')\ntest = loading_cleaned_data('english-french-test.pkl')","metadata":{"id":"h-_XKg-UMojw","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:12.495759Z","iopub.execute_input":"2025-01-29T17:02:12.495995Z","iopub.status.idle":"2025-01-29T17:02:12.612746Z","shell.execute_reply.started":"2025-01-29T17:02:12.495973Z","shell.execute_reply":"2025-01-29T17:02:12.611985Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"**Creating a tokenizer for the lines and finding the maximum length phrase**","metadata":{"id":"Avp8Q0-xdaUj"}},{"cell_type":"code","source":"# fit a tokenizer\ndef create_tokenizer(lines):\n\ttokenizer = Tokenizer()\n\ttokenizer.fit_on_texts(lines)\n\treturn tokenizer\n\n# max sentence length\ndef max_length(lines):\n\treturn max(len(line.split()) for line in lines)","metadata":{"id":"wLD8OFAIPJUf","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:12.613937Z","iopub.execute_input":"2025-01-29T17:02:12.614172Z","iopub.status.idle":"2025-01-29T17:02:12.618275Z","shell.execute_reply.started":"2025-01-29T17:02:12.614152Z","shell.execute_reply":"2025-01-29T17:02:12.617434Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**Size of English & French vocabulary and their max phrase length**","metadata":{"id":"cKvmKQxWeRPQ"}},{"cell_type":"code","source":"# preparing the english tokenizer\n\neng_tokenizer = create_tokenizer(dataset[:, 0])\neng_vocab_size = len(eng_tokenizer.word_index) + 1\neng_length = max_length(dataset[:, 0])\n\nprint('English Vocabulary Size: %d' % eng_vocab_size)\nprint('English Max Length: %d' % (eng_length))\n\n# preparing the french tokenizer\n\nfra_tokenizer = create_tokenizer(dataset[:, 1])\nfra_vocab_size = len(fra_tokenizer.word_index) + 1\nfra_length = max_length(dataset[:, 1])\nprint('French Vocabulary Size: %d' % fra_vocab_size)\nprint('French Max Length: %d' % (fra_length))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDijv11iQ6CX","outputId":"f33fe371-70a9-411b-aedd-d63f8e3fbe74","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:12.618949Z","iopub.execute_input":"2025-01-29T17:02:12.619207Z","iopub.status.idle":"2025-01-29T17:02:13.058144Z","shell.execute_reply.started":"2025-01-29T17:02:12.619188Z","shell.execute_reply":"2025-01-29T17:02:13.057495Z"}},"outputs":[{"name":"stdout","text":"English Vocabulary Size: 3316\nEnglish Max Length: 5\nFrench Vocabulary Size: 6875\nFrench Max Length: 11\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**Encoding to integers and padding to the maximum phrase length**","metadata":{"id":"X3k5O2spejJH"}},{"cell_type":"code","source":"# Input and Output sequence must be encoded to integers and padded to the maximum phrase length\ndef encode_sequences(tokenizer, length, lines):\n\t# integer encode sequences\n\tx = tokenizer.texts_to_sequences(lines)\n\t# pad sequences with 0 values\n\tx = pad_sequences(x, maxlen=length, padding='post')\n\treturn x\n\n# One hot encoding to max phrase length\ndef one_hot_encoding(sequences, vocab_size):\n\ty_1 = list()\n\tfor sequence in sequences:\n\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n\t\ty_1.append(encoded)\n\ty = array(y_1)\n\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n\treturn y","metadata":{"id":"8WECbBTNRG5W","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:13.058843Z","iopub.execute_input":"2025-01-29T17:02:13.059047Z","iopub.status.idle":"2025-01-29T17:02:13.063829Z","shell.execute_reply.started":"2025-01-29T17:02:13.059030Z","shell.execute_reply":"2025-01-29T17:02:13.062971Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"**Training and Testing Data**","metadata":{"id":"9dvj7nZWf8c-"}},{"cell_type":"code","source":"# preparing training data\ntrainX = encode_sequences(fra_tokenizer, fra_length, train[:, 1])\ntrainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\ntrainY = one_hot_encoding(trainY, eng_vocab_size)\n\n# prepare testing data\ntestX = encode_sequences(fra_tokenizer, fra_length, test[:, 1])\ntestY = encode_sequences(eng_tokenizer,eng_length, test[:, 0])\ntestY = one_hot_encoding(testY, eng_vocab_size)","metadata":{"id":"nj7j2bIWf78M","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:13.064491Z","iopub.execute_input":"2025-01-29T17:02:13.064731Z","iopub.status.idle":"2025-01-29T17:02:16.308997Z","shell.execute_reply.started":"2025-01-29T17:02:13.064706Z","shell.execute_reply":"2025-01-29T17:02:16.308059Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"print('training size:',trainX.shape,trainY.shape)\nprint('testing size:',testX.shape,testY.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8xr_mwyFdRD","outputId":"c4e25354-f84b-4886-c5f7-0d3f6a53ec5d","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:16.310033Z","iopub.execute_input":"2025-01-29T17:02:16.310355Z","iopub.status.idle":"2025-01-29T17:02:16.315797Z","shell.execute_reply.started":"2025-01-29T17:02:16.310324Z","shell.execute_reply":"2025-01-29T17:02:16.315080Z"}},"outputs":[{"name":"stdout","text":"training size: (18000, 11) (18000, 5, 3316)\ntesting size: (2000, 11) (2000, 5, 3316)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**Building the model**","metadata":{"id":"bs628M3JgpLZ"}},{"cell_type":"code","source":"def model_building(source_vocab, target_vocab, source_len, target_len, units):\n\tmodel = Sequential()\n\tmodel.add(Embedding(source_vocab, units, input_length=source_len, mask_zero=True))\n\tmodel.add(LSTM(units))\n\tmodel.add(RepeatVector(target_len))\n\tmodel.add(LSTM(units, return_sequences=True))\n\tmodel.add(TimeDistributed(Dense(target_vocab, activation='softmax')))\n\treturn model","metadata":{"id":"pBlM7AzcR-U_","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:16.316498Z","iopub.execute_input":"2025-01-29T17:02:16.316795Z","iopub.status.idle":"2025-01-29T17:02:16.328026Z","shell.execute_reply.started":"2025-01-29T17:02:16.316768Z","shell.execute_reply":"2025-01-29T17:02:16.327342Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"**Defining and Compiling the model**","metadata":{"id":"HexQi4N7iLln"}},{"cell_type":"code","source":"model = model_building(fra_vocab_size, eng_vocab_size, fra_length, eng_length, 512)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])","metadata":{"id":"wOrjJUy8SECu","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:16.328701Z","iopub.execute_input":"2025-01-29T17:02:16.328968Z","iopub.status.idle":"2025-01-29T17:02:17.311897Z","shell.execute_reply.started":"2025-01-29T17:02:16.328930Z","shell.execute_reply":"2025-01-29T17:02:17.311004Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"**Model Summary**","metadata":{"id":"V3ovCukmiRzW"}},{"cell_type":"code","source":"print(model.summary())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwb8ibuDSUvW","outputId":"cb158472-223e-4e30-a233-5744b7c2460d","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:17.312738Z","iopub.execute_input":"2025-01-29T17:02:17.313070Z","iopub.status.idle":"2025-01-29T17:02:17.329936Z","shell.execute_reply.started":"2025-01-29T17:02:17.313044Z","shell.execute_reply":"2025-01-29T17:02:17.329092Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Stop model if accuracy of the model doesn't changes by more than 0.01 \n# Patience = 5 : After each 5 epochs if no improvement is there then training will be stopped.\nfrom tensorflow.keras.callbacks import EarlyStopping\nes = EarlyStopping(monitor='val_acc',patience= 5,min_delta=0.01)","metadata":{"id":"d3_4Jn4RkNU9","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:17.330765Z","iopub.execute_input":"2025-01-29T17:02:17.331063Z","iopub.status.idle":"2025-01-29T17:02:17.337802Z","shell.execute_reply.started":"2025-01-29T17:02:17.331033Z","shell.execute_reply":"2025-01-29T17:02:17.336996Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"**Fitting the model**\n\n1.Epochs = 50\n\n2.Batch_size = 25","metadata":{"id":"8VP_QQwGiZrN"}},{"cell_type":"code","source":"# fit model\nmodel.fit(trainX, trainY, epochs= 50, batch_size=25, validation_data=(testX, testY), verbose=2,callbacks=[es])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BI6ioDuaS57H","outputId":"c166b7d8-49b9-4416-927a-7722c7350d54","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:02:17.338735Z","iopub.execute_input":"2025-01-29T17:02:17.339015Z","iopub.status.idle":"2025-01-29T17:04:50.738294Z","shell.execute_reply.started":"2025-01-29T17:02:17.338979Z","shell.execute_reply":"2025-01-29T17:04:50.737417Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n720/720 - 17s - 23ms/step - acc: 0.4768 - loss: 3.4779 - val_acc: 0.5437 - val_loss: 2.9136\nEpoch 2/50\n720/720 - 9s - 12ms/step - acc: 0.5710 - loss: 2.5870 - val_acc: 0.6071 - val_loss: 2.3889\nEpoch 3/50\n720/720 - 9s - 12ms/step - acc: 0.6268 - loss: 2.0455 - val_acc: 0.6329 - val_loss: 2.1138\nEpoch 4/50\n720/720 - 9s - 12ms/step - acc: 0.6750 - loss: 1.6283 - val_acc: 0.6617 - val_loss: 1.8967\nEpoch 5/50\n720/720 - 9s - 12ms/step - acc: 0.7187 - loss: 1.2831 - val_acc: 0.6839 - val_loss: 1.7369\nEpoch 6/50\n720/720 - 9s - 12ms/step - acc: 0.7682 - loss: 0.9846 - val_acc: 0.7007 - val_loss: 1.6391\nEpoch 7/50\n720/720 - 9s - 12ms/step - acc: 0.8115 - loss: 0.7503 - val_acc: 0.7124 - val_loss: 1.5802\nEpoch 8/50\n720/720 - 9s - 12ms/step - acc: 0.8478 - loss: 0.5696 - val_acc: 0.7277 - val_loss: 1.5394\nEpoch 9/50\n720/720 - 9s - 12ms/step - acc: 0.8775 - loss: 0.4429 - val_acc: 0.7270 - val_loss: 1.5403\nEpoch 10/50\n720/720 - 9s - 12ms/step - acc: 0.8982 - loss: 0.3540 - val_acc: 0.7310 - val_loss: 1.5466\nEpoch 11/50\n720/720 - 9s - 12ms/step - acc: 0.9117 - loss: 0.2943 - val_acc: 0.7380 - val_loss: 1.5475\nEpoch 12/50\n720/720 - 9s - 13ms/step - acc: 0.9197 - loss: 0.2563 - val_acc: 0.7349 - val_loss: 1.5661\nEpoch 13/50\n720/720 - 9s - 13ms/step - acc: 0.9241 - loss: 0.2326 - val_acc: 0.7390 - val_loss: 1.5841\nEpoch 14/50\n720/720 - 9s - 12ms/step - acc: 0.9280 - loss: 0.2170 - val_acc: 0.7408 - val_loss: 1.6037\nEpoch 15/50\n720/720 - 9s - 12ms/step - acc: 0.9296 - loss: 0.2055 - val_acc: 0.7409 - val_loss: 1.6342\nEpoch 16/50\n720/720 - 9s - 12ms/step - acc: 0.9309 - loss: 0.1964 - val_acc: 0.7372 - val_loss: 1.6385\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f37e4fe0af0>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"**Evaluating model and calculating BLEU Score**","metadata":{"id":"PamgrtO1tc81"}},{"cell_type":"markdown","source":"Evaluation involves two steps: \n\n1.Generating a translated output sequence, and \n\n2.then repeating this process for many input examples and summarizing the skill of the model across multiple cases.","metadata":{"id":"5jpeIlnvNTyK"}},{"cell_type":"code","source":"# mapping integer to a word\ndef word_for_id(integer, tokenizer):\n\tfor word, index in tokenizer.word_index.items():\n\t\tif index == integer:\n\t\t\treturn word\n\treturn None","metadata":{"id":"vjz4ERSYT1Df","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:04:50.739331Z","iopub.execute_input":"2025-01-29T17:04:50.739565Z","iopub.status.idle":"2025-01-29T17:04:50.743347Z","shell.execute_reply.started":"2025-01-29T17:04:50.739545Z","shell.execute_reply":"2025-01-29T17:04:50.742531Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# generating target given source sequence\ndef predict_sequence(model, tokenizer, source):\n\tprediction = model.predict(source, verbose=0)[0]\n\tintegers = [argmax(vector) for vector in prediction]\n\ttarget = list()\n\tfor i in integers:\n\t\tword = word_for_id(i, tokenizer)\n\t\tif word is None:\n\t\t\tbreak\n\t\ttarget.append(word)\n\treturn ' '.join(target)","metadata":{"id":"XZV4Qm51TxdH","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:04:50.744198Z","iopub.execute_input":"2025-01-29T17:04:50.744473Z","iopub.status.idle":"2025-01-29T17:04:50.756971Z","shell.execute_reply.started":"2025-01-29T17:04:50.744453Z","shell.execute_reply":"2025-01-29T17:04:50.756193Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"\n# evaluating the skill of the model\ndef evaluate_model(model, tokenizer, sources, raw_dataset):\n  \n  # Creating empty lists for actual phrases(French) and predicted phrases(English) \n  actual,predicted = list(),list()\n  a,b,c = list(),list(),list()\n  for i,source in enumerate(sources):\n\n    # reshaping to the required size\n    source = source.reshape((1, source.shape[0]))\n\n    # predicting for the english tokenizer\n    translation = predict_sequence(model, eng_tokenizer, source)\n    # raw_dataset = raw_dataset[i].split(' ') \n    # print(raw_dataset[i][1])\n\n    raw_src,raw_target = raw_dataset[i][1],raw_dataset[i][0]\n    \n    # First 10 Predictions\n    if i <= 10:\n      print('source = ',raw_src,'<--->', ' target = ',raw_target,'<--->','  predicted = ',translation)\n\n    actual.append([raw_target.split()])\n    predicted.append(translation.split())\n  \n  # calculating BLEU score\n  print('-------------------------------------------')\n  print('BLEU Score :')\n  print('BLEU score-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0),smoothing_function=smoothie,auto_reweigh=False))\n  print('BLEU score-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0),smoothing_function=smoothie,auto_reweigh=False))\n  print('BLEU score-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0),smoothing_function=smoothie,auto_reweigh=False))\n  print('BLEU score-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25),smoothing_function=smoothie,auto_reweigh=False))","metadata":{"id":"_pHVBAejXOA1","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:04:50.757766Z","iopub.execute_input":"2025-01-29T17:04:50.758019Z","iopub.status.idle":"2025-01-29T17:04:50.768762Z","shell.execute_reply.started":"2025-01-29T17:04:50.757983Z","shell.execute_reply":"2025-01-29T17:04:50.768099Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n\nsmoothie = SmoothingFunction().method4  # Define smoothing function","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:22:22.933342Z","iopub.execute_input":"2025-01-29T17:22:22.933669Z","iopub.status.idle":"2025-01-29T17:22:23.868070Z","shell.execute_reply.started":"2025-01-29T17:22:22.933624Z","shell.execute_reply":"2025-01-29T17:22:23.867364Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"**Evaluating Model on training data**","metadata":{"id":"TnrScoRlPafY"}},{"cell_type":"code","source":"evaluate_model(model,eng_tokenizer,trainX,train)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q42oWYQuWhSw","outputId":"90053f9b-4d1d-4300-d37d-75067581ab39","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:22:26.904089Z","iopub.execute_input":"2025-01-29T17:22:26.904910Z","iopub.status.idle":"2025-01-29T17:38:51.376970Z","shell.execute_reply.started":"2025-01-29T17:22:26.904878Z","shell.execute_reply":"2025-01-29T17:38:51.376175Z"}},"outputs":[{"name":"stdout","text":"source =  cela pourrait etre tom <--->  target =  it could be tom <--->   predicted =  it could be tom\nsource =  nous avons rompu <--->  target =  we broke up <--->   predicted =  we broke up\nsource =  bouge <--->  target =  get out <--->   predicted =  go away\nsource =  tom est serieux <--->  target =  tom is serious <--->   predicted =  tom means\nsource =  estu enceinte <--->  target =  are you pregnant <--->   predicted =  are you pregnant\nsource =  tu as le cancer <--->  target =  you have cancer <--->   predicted =  you have cancer\nsource =  aidemoi a me lever <--->  target =  help me get up <--->   predicted =  help me get up\nsource =  je suis toubib <--->  target =  im a doctor <--->   predicted =  im a doctor\nsource =  tu es mon patron <--->  target =  youre my boss <--->   predicted =  youre my boss\nsource =  dites ce que vous pensez <--->  target =  speak your mind <--->   predicted =  speak your mind\nsource =  il le mentionna <--->  target =  he mentioned it <--->   predicted =  he mentioned it\n-------------------------------------------\nBLEU Score :\nBLEU score-1: 0.924081\nBLEU score-2: 0.900588\nBLEU score-3: 0.834462\nBLEU score-4: 0.556245\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"**Evaluating Model on testing data**","metadata":{"id":"sgxS1flZPjNJ"}},{"cell_type":"code","source":"evaluate_model(model, eng_tokenizer, testX, test)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QIsBhu9N5wfx","outputId":"a45d7f83-50f1-49e6-c081-4ea9026ad9c5","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:44:24.101012Z","iopub.execute_input":"2025-01-29T17:44:24.101227Z","iopub.status.idle":"2025-01-29T17:46:17.486287Z","shell.execute_reply.started":"2025-01-29T17:44:24.101209Z","shell.execute_reply":"2025-01-29T17:46:17.485398Z"}},"outputs":[{"name":"stdout","text":"source =  pas grave <--->  target =  skip it <--->   predicted =  lets try\nsource =  cest ma voiture <--->  target =  this cars mine <--->   predicted =  this is my car\nsource =  pensestu la meme chose <--->  target =  do you think so <--->   predicted =  thanks like dream\nsource =  monte le cheval <--->  target =  get on the horse <--->   predicted =  get your the horse\nsource =  nous sommes impliques <--->  target =  were involved <--->   predicted =  were involved\nsource =  nous sommes ennemis <--->  target =  were enemies <--->   predicted =  were enemies\nsource =  laije emporte <--->  target =  did i win <--->   predicted =  did i win\nsource =  je ne peux pas admettre ma defaite <--->  target =  i cant give up <--->   predicted =  i cant give up\nsource =  il faut que je sois aveugle <--->  target =  i must be blind <--->   predicted =  i must to hurry\nsource =  je deteste les tomates <--->  target =  i hate tomatoes <--->   predicted =  i hate liars\nsource =  je suis tres triste <--->  target =  i am very sad <--->   predicted =  im very sad\n-------------------------------------------\nBLEU Score :\nBLEU score-1: 0.613324\nBLEU score-2: 0.511021\nBLEU score-3: 0.440260\nBLEU score-4: 0.238901\n","output_type":"stream"}],"execution_count":33}]}